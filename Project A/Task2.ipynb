{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation in MHIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "from Utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 1545\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "path = \"mhist_dataset/images\"\n",
    "CSVfile = \"mhist_dataset/annotations.csv\"\n",
    "\n",
    "data, file_names = load_mhist_images(path)\n",
    "X_train, y_train, X_test, y_test = loadMHIST(CSVfile,data)\n",
    "\n",
    "# Data Augmentation\n",
    "AugmentedData = []\n",
    "AugmentedLabel = []\n",
    "for i in range(len(X_train)):\n",
    "    if((y_train[i]==(1,0)).all()):\n",
    "        AugmentedData.append(cv2.rotate(X_train[i], cv2.ROTATE_90_CLOCKWISE))\n",
    "        AugmentedLabel.append([1,0])\n",
    "X_train = np.concatenate((X_train, AugmentedData))\n",
    "y_train = np.concatenate((y_train, AugmentedLabel))\n",
    "c = list(zip(X_train, y_train))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "X_train, y_train = zip(*c)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "Train_Data, Train_Label, Test_Data, Test_Label = dataBatching(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Teacher Model\n",
    "restNet = getresnetModel()\n",
    "\n",
    "## Load Student Model for KD\n",
    "mobileNetKD = getMobileNetModel()\n",
    "\n",
    "## Load Student Model for from scratch training\n",
    "mobileNet = getMobileNetModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Teacher Model (Resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 59.03%\n",
      "Epoch 2: Class_accuracy: 42.86%\n",
      "Epoch 1: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Task2.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_and_evaluate(restNet,Train_Data,Test_Data,Train_Label,Test_Label,\u001b[39m2\u001b[39m, \u001b[39m0.0001\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## Fine tune epochs at learning rate 0.00001\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_and_evaluate(restNet,Train_Data,Test_Data,Train_Label,Test_Label,\u001b[39m2\u001b[39;49m, \u001b[39m0.00001\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Utilities.py:239\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, trainingData, testingData, trainingLabel, testLabel, nEpochs, learingRate)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(trainingData)):\n\u001b[0;32m    238\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 239\u001b[0m         loss_value \u001b[39m=\u001b[39m compute_loss(model,trainingData[i],trainingLabel[i])\n\u001b[0;32m    240\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss_value, model\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m    241\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, model\u001b[39m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1868\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n\u001b[0;32m   1867\u001b[0m \u001b[39mif\u001b[39;00m executing_eagerly:\n\u001b[1;32m-> 1868\u001b[0m   flat_outputs \u001b[39m=\u001b[39m forward_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1869\u001b[0m       ctx, args_with_tangents, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager)\n\u001b[0;32m   1870\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1871\u001b[0m   \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_override_gradient_function(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1872\u001b[0m       {\u001b[39m\"\u001b[39m\u001b[39mPartitionedCall\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_gradient_function(),\n\u001b[0;32m   1873\u001b[0m        \u001b[39m\"\u001b[39m\u001b[39mStatefulPartitionedCall\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_gradient_function()}):\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## intial epochs at learning rate 0.0001\n",
    "train_and_evaluate(restNet,Train_Data,Test_Data,Train_Label,Test_Label,10, 0.0001)\n",
    "## Fine tune epochs at learning rate 0.00001\n",
    "train_and_evaluate(restNet,Train_Data,Test_Data,Train_Label,Test_Label,25, 0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Student Mobile Net using KD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 61.21%\n",
      "Epoch 2: Class_accuracy: 58.73%\n",
      "Epoch 3: Class_accuracy: 35.71%\n",
      "Epoch 4: Class_accuracy: 35.71%\n",
      "Epoch 5: Class_accuracy: 37.50%\n",
      "Epoch 6: Class_accuracy: 47.72%\n",
      "Epoch 7: Class_accuracy: 47.92%\n",
      "Epoch 8: Class_accuracy: 37.80%\n",
      "Epoch 9: Class_accuracy: 42.46%\n",
      "Epoch 10: Class_accuracy: 50.69%\n",
      "Epoch 1: Class_accuracy: 41.27%\n",
      "Epoch 2: Class_accuracy: 43.15%\n",
      "Epoch 3: Class_accuracy: 41.47%\n",
      "Epoch 4: Class_accuracy: 41.96%\n",
      "Epoch 5: Class_accuracy: 41.47%\n",
      "Epoch 6: Class_accuracy: 41.57%\n",
      "Epoch 7: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Task2.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_and_evaluate_mobileNet_using_KD(mobileNetKD,restNet,Train_Data,Test_Data,Train_Label,Test_Label, \u001b[39m0.5\u001b[39m,\u001b[39m4\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m0.001\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## Fine tune epochs\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_and_evaluate_mobileNet_using_KD(mobileNetKD,restNet,Train_Data,Test_Data,Train_Label,Test_Label, \u001b[39m0.5\u001b[39;49m,\u001b[39m4\u001b[39;49m, \u001b[39m25\u001b[39;49m, \u001b[39m0.0001\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Utilities.py:269\u001b[0m, in \u001b[0;36mtrain_and_evaluate_mobileNet_using_KD\u001b[1;34m(studentModel, teacherModel, trainingData, testingData, trainingLabel, testLabel, alpha, temprature, nEpochs, learingRate)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m    268\u001b[0m         loss_value \u001b[39m=\u001b[39m compute_student_loss_using_KD(studentModel, teacherModel,trainingData[i],trainingLabel[i], alpha, temprature)\n\u001b[1;32m--> 269\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss_value, studentModel\u001b[39m.\u001b[39;49mtrainable_variables)\n\u001b[0;32m    270\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, studentModel\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m    272\u001b[0m \u001b[39m# Run evaluation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:674\u001b[0m, in \u001b[0;36m_zeros\u001b[1;34m(shape, dtype)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fast_fill\u001b[39m(value, shape, dtype):\n\u001b[0;32m    669\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39mfill(\n\u001b[0;32m    670\u001b[0m       constant_op\u001b[39m.\u001b[39mconstant(shape, dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32),\n\u001b[0;32m    671\u001b[0m       constant_op\u001b[39m.\u001b[39mconstant(value, dtype\u001b[39m=\u001b[39mdtype))\n\u001b[1;32m--> 674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_zeros\u001b[39m(shape, dtype):\n\u001b[0;32m    675\u001b[0m   \u001b[39m\"\"\"Helper to return (possibly cached) zero tensors in eager mode.\"\"\"\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39m# Note: variants will use _zeros_like\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## intial epochs\n",
    "train_and_evaluate_mobileNet_using_KD(mobileNetKD,restNet,Train_Data,Test_Data,Train_Label,Test_Label, 0.5,4, 10, 0.001)\n",
    "## Fine tune epochs\n",
    "train_and_evaluate_mobileNet_using_KD(mobileNetKD,restNet,Train_Data,Test_Data,Train_Label,Test_Label, 0.5,4, 25, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train another student model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 59.23%\n",
      "Epoch 2: Class_accuracy: 59.82%\n",
      "Epoch 3: Class_accuracy: 38.29%\n",
      "Epoch 4: Class_accuracy: 37.70%\n",
      "Epoch 5: Class_accuracy: 58.73%\n",
      "Epoch 6: Class_accuracy: 45.44%\n",
      "Epoch 7: Class_accuracy: 39.29%\n",
      "Epoch 8: Class_accuracy: 37.10%\n",
      "Epoch 9: Class_accuracy: 47.72%\n",
      "Epoch 10: Class_accuracy: 55.95%\n",
      "Epoch 1: Class_accuracy: 41.87%\n",
      "Epoch 2: Class_accuracy: 41.57%\n",
      "Epoch 3: Class_accuracy: 41.96%\n",
      "Epoch 4: Class_accuracy: 41.96%\n",
      "Epoch 5: Class_accuracy: 41.67%\n",
      "Epoch 6: Class_accuracy: 41.67%\n",
      "Epoch 7: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Task2.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_and_evaluate(mobileNet,Train_Data,Test_Data,Train_Label,Test_Label,\u001b[39m10\u001b[39m, \u001b[39m0.001\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m## Fine tune epochs\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/khoda/OneDrive/Documents/repos/ECE1512-2022F-ProjectARepo-Ayman-Farnaz/Project%20A/Task2.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_and_evaluate(mobileNet,Train_Data,Test_Data,Train_Label,Test_Label,\u001b[39m25\u001b[39;49m, \u001b[39m0.0001\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\khoda\\OneDrive\\Documents\\repos\\ECE1512-2022F-ProjectARepo-Ayman-Farnaz\\Project A\\Utilities.py:240\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, trainingData, testingData, trainingLabel, testLabel, nEpochs, learingRate)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m    239\u001b[0m         loss_value \u001b[39m=\u001b[39m compute_loss(model,trainingData[i],trainingLabel[i])\n\u001b[1;32m--> 240\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss_value, model\u001b[39m.\u001b[39;49mtrainable_variables)\n\u001b[0;32m    241\u001b[0m     optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, model\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m    243\u001b[0m \u001b[39m# Run evaluation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## intial epochs\n",
    "train_and_evaluate(mobileNet,Train_Data,Test_Data,Train_Label,Test_Label,10, 0.001)\n",
    "## Fine tune epochs\n",
    "train_and_evaluate(mobileNet,Train_Data,Test_Data,Train_Label,Test_Label,25, 0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Testing Accuracy: 39.68%\n",
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "5\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# model testing\n",
    "teacherAcc = testTransferedModel(restNet,Test_Data,Test_Label)\n",
    "studentAcc = testTransferedModel(mobileNet,Test_Data,Test_Label)\n",
    "studentAccKD = testTransferedModel(mobileNetKD,Test_Data,Test_Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 38.69%\n",
      "Epoch 2: Class_accuracy: 35.62%\n",
      "model Testing Accuracy: 35.62%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 44.15%\n",
      "Epoch 2: Class_accuracy: 35.81%\n",
      "model Testing Accuracy: 35.81%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 2: Class_accuracy: 35.71%\n",
      "model Testing Accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 2: Class_accuracy: 35.71%\n",
      "model Testing Accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 2: Class_accuracy: 35.71%\n",
      "model Testing Accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 1: Class_accuracy: 35.71%\n",
      "Epoch 2: Class_accuracy: 35.71%\n",
      "model Testing Accuracy: 35.71%\n",
      "[<tf.Tensor: shape=(), dtype=float32, numpy=35.61508>, <tf.Tensor: shape=(), dtype=float32, numpy=35.81349>, <tf.Tensor: shape=(), dtype=float32, numpy=35.714287>, <tf.Tensor: shape=(), dtype=float32, numpy=35.714287>, <tf.Tensor: shape=(), dtype=float32, numpy=35.714287>, <tf.Tensor: shape=(), dtype=float32, numpy=35.714287>]\n"
     ]
    }
   ],
   "source": [
    "testACC = []\n",
    "tempratureValues = [1, 2, 4, 16, 32, 64]\n",
    "for temp in tempratureValues:\n",
    "    st = getMobileNetModel()\n",
    "    train_and_evaluate_mobileNet_using_KD(st,restNet,Train_Data,Test_Data,Train_Label,Test_Label, 0.5,temp, 10, 0.001)\n",
    "    train_and_evaluate_mobileNet_using_KD(st,restNet,Train_Data,Test_Data,Train_Label,Test_Label, 0.5,temp, 25, 0.0001)\n",
    "    testACC += [testTransferedModel(st,Test_Data,Test_Label)]\n",
    "print(testACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 4))\n",
    "tempratureValues = [1, 2, 4, 16, 32, 64]\n",
    "testACC = [50, 60 , 70, 80 , 90, 100]\n",
    "ax.plot(tempratureValues,testACC )\n",
    "ax.set_xlabel('Temperature', fontsize = 16)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize = 16)\n",
    "ax.set_title(' Testing Accuracy of Student Model trained using KD Accuracy', fontsize = 20)\n",
    "ax.legend()\n",
    "plt.show()\n",
    "f.savefig('Figures/fig7.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_3[0][0]',        \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_4[0][0]',        \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_5[0][0]',        \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 100352)       0           ['post_relu[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 2)            200706      ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,765,506\n",
      "Trainable params: 1,255,426\n",
      "Non-trainable params: 22,510,080\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_5[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 62720)        0           ['out_relu[0][0]']               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            125442      ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,383,426\n",
      "Trainable params: 845,442\n",
      "Non-trainable params: 1,537,984\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From c:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5219: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\khoda\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5219: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 6.99 G\n",
      "FLOPS: 0.613 G\n"
     ]
    }
   ],
   "source": [
    "# your code start from here for step 8\n",
    "from keras_flops import get_flops\n",
    "TeacherParameters = restNet.summary()\n",
    "StudentParameters = mobileNetKD.summary()\n",
    "\n",
    "flops = get_flops(restNet, batch_size=1)\n",
    "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "\n",
    "flops = get_flops(mobileNetKD, batch_size=1)\n",
    "print(f\"FLOPS: {flops / 10 ** 9:.03} G\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "680419e0188aaa6743f4a0e8f0e13458aa11f8cd04d9d5e558d5d63e6a49fb4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
